# ðŸ“¦ Install dependencies
!pip install -q tensorflow scikit-learn matplotlib

import os, random
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.applications import EfficientNetV2S
from tensorflow.keras import layers, models
from sklearn.metrics import precision_score, recall_score, roc_auc_score
import matplotlib.pyplot as plt

# âœ… Reproducibility
seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)
random.seed(seed)

# âœ… Paths
base_dir = '/content/data_splitting/data_splitting/train'
num_classes = 4
img_size = (224, 224)
batch_size = 32
val_split = 0.2

# âœ… Dataset (train/val split)
train_ds = image_dataset_from_directory(
    base_dir,
    validation_split=val_split,
    subset="training",
    seed=seed,
    image_size=img_size,
    batch_size=batch_size
)

val_ds = image_dataset_from_directory(
    base_dir,
    validation_split=val_split,
    subset="validation",
    seed=seed,
    image_size=img_size,
    batch_size=batch_size
)

class_names = train_ds.class_names

# âœ… Prefetch for performance
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)

# âœ… Model Setup
base_model = EfficientNetV2S(include_top=False, weights="imagenet", input_shape=img_size + (3,))
base_model.trainable = False  # freeze base

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.3),
    layers.Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# âœ… Custom Callback for Precision, Recall, AUC
class MetricsCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        y_true, y_pred, y_prob = [], [], []
        for images, labels in val_ds:
            preds = self.model.predict(images, verbose=0)
            y_true.extend(labels.numpy())
            y_pred.extend(np.argmax(preds, axis=1))
            y_prob.extend(preds)

        prec = precision_score(y_true, y_pred, average="macro")
        rec = recall_score(y_true, y_pred, average="macro")
        try:
            auc = roc_auc_score(tf.keras.utils.to_categorical(y_true, num_classes),
                                y_prob, multi_class="ovr")
        except:
            auc = 0.0

        print(f" â€” val_precision: {prec:.3f} â€” val_recall: {rec:.3f} â€” val_auc: {auc:.3f}")

# âœ… Callbacks
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True),
    tf.keras.callbacks.ModelCheckpoint("best_efficientnetv2s_tf.h5", save_best_only=True),
    MetricsCallback()
]

# âœ… Training
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=25,
    callbacks=callbacks
)

# âœ… Save final trained model in Keras format
model.save("/content/efficientnetv2s.keras", save_format="keras")
print("âœ… Final model saved as efficientnetv2s.keras")

# âœ… Plot Loss & Accuracy
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.title("Loss per Epoch"); plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["accuracy"], label="Train Acc")
plt.plot(history.history["val_accuracy"], label="Val Acc")
plt.title("Accuracy per Epoch"); plt.legend()
plt.show()
